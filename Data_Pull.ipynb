{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "from pandas_datareader import data as pdr\n",
    "from googlefinance.client import get_price_data, get_prices_data, get_prices_time_data\n",
    "import fix_yahoo_finance as yf\n",
    "import pyodbc \n",
    "import os\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download lists of all companies in All US exchanges.  Catch Error if urls become outdated.  \n",
    "NASDAQ_url = 'http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NASDAQ&render=download'\n",
    "NYSE_url = 'http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NYSE&render=download'\n",
    "AMEX_url = 'http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=AMEX&render=download'\n",
    "try:\n",
    "    response = urllib.request.urlopen(NASDAQ_url)\n",
    "    NASDAQ_df = pd.read_csv(response)\n",
    "    \n",
    "    response = urllib.request.urlopen(NYSE_url)\n",
    "    NYSE_df = pd.read_csv(response)\n",
    "    \n",
    "    response = urllib.request.urlopen(AMEX_url)\n",
    "    AMEX_df = pd.read_csv(response)\n",
    "    \n",
    "    df=NASDAQ_df\n",
    "    df=df.append(NYSE_df)\n",
    "    df=df.append(AMEX_df)\n",
    "\n",
    "    df=df.drop_duplicates('Symbol')\n",
    "    df=df.set_index('Symbol')\n",
    "    df=df.sort_values(by=['MarketCap'],ascending=False)\n",
    "    \n",
    "    #Only want companies with positive market cap\n",
    "    df=df[df['MarketCap']>0]\n",
    "    \n",
    "except Exception:\n",
    "    print(\"Download Fail\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Runs everyday to update historical data and add new stock data to database\n",
    "cnxn = pyodbc.connect(\"Driver={SQL Server Native Client 11.0};\"\n",
    "                      \"Server=localhost\\SQLEXPRESS;\"\n",
    "                      \"Database=Stock_Data;\"\n",
    "                      \"Trusted_Connection=yes;\")\n",
    "\n",
    "end_date=today=datetime.datetime.now()\n",
    "start_date= '2000-01-01'\n",
    "directory_prices = r'C:\\Users\\Chris Atkeson\\Documents\\Market_Data\\saved_data'\n",
    "directory_ticker=r'C:\\Users\\Chris Atkeson\\Documents\\Market_Data'\n",
    "num_runs=10\n",
    "successful_downloads,failed_downloads=fill_history(start_date,end_date,df,directory_prices,num_runs,cnxn,directory_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs before analysis\n",
    "directory = r'C:\\Users\\Chris Atkeson\\Documents\\Market_Data\\saved_data'\n",
    "\n",
    "cnxn = pyodbc.connect(\"Driver={SQL Server Native Client 11.0};\"\n",
    "                      \"Server=localhost\\SQLEXPRESS;\"\n",
    "                      \"Database=Stock_Data;\"\n",
    "                      \"Trusted_Connection=yes;\")\n",
    "\n",
    "#write_to_sql(cnxn,directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull yahoo finance historical data for all companies with positive Market Capital using exchange list.  \n",
    "def fill_history(start_date,end_date,df,directory,num_runs,cnxn,directory_ticker):\n",
    "    \n",
    "    update_tickers(df,end_date,cnxn,directory_ticker)\n",
    "    \n",
    "    failed_downloads=[]\n",
    "    success_downloads=[]\n",
    "\n",
    "    for i,row in df.iterrows():\n",
    "        symbol=i\n",
    "        market_cap=row['MarketCap']\n",
    "        nasdaq_price=row['LastSale']\n",
    "        sector=row['Sector']\n",
    "    \n",
    "        if market_cap > 0:\n",
    "            try:\n",
    "                df_yahoo=pdr.get_data_yahoo(symbol,start_date,end_date,progress=False)\n",
    "                df_yahoo['ticker']=symbol\n",
    "                df_yahoo.to_csv(directory + '\\\\' + symbol +'.csv')\n",
    "                success_downloads.append(symbol)\n",
    "            except Exception as e:\n",
    "                failed_downloads.append(symbol)\n",
    "    \n",
    "    for x in range (0,num_runs):\n",
    "        print(\"Total Failed Downloads: \" + str(len(failed_downloads)) + \" Total Success Downloads: \" + str(len(success_downloads)) + \" Time: \" + str(datetime.datetime.now()))\n",
    "        failed_downloads,success_downloads=fill_hist_help(start_date,end_date,failed_downloads,directory,success_downloads)\n",
    "        \n",
    "    return (failed_downloads,success_downloads)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for re-running failed downloads\n",
    "def fill_hist_help(start_date,end_date,symbols,directory,success_downloads):\n",
    "    failed_downloads=[]\n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            df_yahoo=pdr.get_data_yahoo(symbol,start_date,end_date,progress=False)\n",
    "            df_yahoo['ticker']=symbol\n",
    "            df_yahoo.to_csv(directory + '\\\\' + symbol +'.csv')\n",
    "            success_downloads.append(symbol)\n",
    "        except Exception as e:\n",
    "            failed_downloads.append(symbol)\n",
    "    return failed_downloads,success_downloads\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write yahoo stock historicall data csv files to one table in database\n",
    "def write_to_sql(cnxn,directory):\n",
    "    count=0\n",
    "    cursor = cnxn.cursor()\n",
    "    SQL_string=r\"\"\"Truncate table [stock_Data].[dbo].[Hist_Data]\"\"\"\n",
    "    cursor.execute(SQL_string)\n",
    "    cursor.close()\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        \n",
    "        #just for general progress tricking\n",
    "        count+=1\n",
    "        if count % 100 == 0:\n",
    "            print(str(count))\n",
    "\n",
    "        if filename.endswith(\".csv\"): \n",
    "            try:\n",
    "                ticker=filename[:-4]\n",
    "                csv_path= \"saved_data\" + \"\\\\\" + filename\n",
    "                cursor = cnxn.cursor()\n",
    "    \n",
    "                SQL_string= (\"BULK INSERT [Stock_Data].[dbo].[Hist_Data] FROM '\"\"\" + \n",
    "                directory + \"\\\\\" + filename + \"\"\"' WITH \n",
    "                (FIRSTROW=2,FIELDTERMINATOR = ',',ROWTERMINATOR = '\\\\n')\"\"\")\n",
    "                \n",
    "                cursor.execute(SQL_string)\n",
    "                cnxn.commit()\n",
    "                cursor.close()\n",
    "            \n",
    "            except Exception:\n",
    "                print(filename[:-4])\n",
    "                cursor.close()\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "    cnxn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save marketcaps and update company master list in database\n",
    "def update_tickers(df,end_date,cnxn,directory):\n",
    "    df=df.where((pd.notnull(df)), None)\n",
    "    df['Name']=df['Name'].str.replace(\",\",\" \")\n",
    "    df['Sector']=df['Sector'].str.replace(\",\",\" \")\n",
    "    df['Industry']=df['Industry'].str.replace(\",\",\" \")\n",
    "    \n",
    "    df[['Name','LastSale','MarketCap','ADR TSO','IPOyear','Sector','Industry','Summary Quote']].to_csv(directory + r'\\Tickers.csv')\n",
    "    df['Date'] = end_date\n",
    "    \n",
    "    df[['MarketCap','Date']].to_csv(directory + r'\\Tickers_Market_Cap.csv')\n",
    "    \n",
    "    cursor = cnxn.cursor()\n",
    "    \n",
    "    SQL_string= \"\"\"Truncate Table Market_Cap_Staging\"\"\"\n",
    "\n",
    "    cursor.execute(SQL_string)\n",
    "    cnxn.commit()\n",
    "    \n",
    "    SQL_String = r\"\"\"BULK INSERT [Stock_Data].[dbo].[Market_Cap_Staging] \n",
    "    FROM\"\"\" + \"\"\" '\"\"\" + directory + \"\"\"\\Tickers_Market_Cap.csv' \"\"\" + \"\"\"WITH (FIRSTROW=2,FIELDTERMINATOR = ',',ROWTERMINATOR = '\\n')\"\"\"\n",
    "    \n",
    "    cursor.execute(SQL_String)\n",
    "    cnxn.commit()\n",
    "    \n",
    "    SQL_string=\"\"\"Merge [Stock_Data].[dbo].[Market_Cap_Hist] as targ\n",
    "    Using [Stock_Data].[dbo].[Market_Cap_Staging] as srce on targ.Ticker=srce.Ticker and targ.Date=srce.Date\n",
    "    When Matched then Update Set targ.MarketCap=srce.MarketCap\n",
    "    When Not Matched then Insert (Ticker,MarketCap,Date) Values (srce.Ticker,srce.MarketCap,srce.Date);\"\"\"\n",
    "\n",
    "    cursor.execute(SQL_string)\n",
    "    cnxn.commit()\n",
    "    \n",
    "    SQL_string= \"\"\"Truncate Table Company_List_Staging\"\"\"\n",
    "\n",
    "    cursor.execute(SQL_string)\n",
    "    cnxn.commit()\n",
    "    \n",
    "    SQL_string = r\"\"\"BULK INSERT [Stock_Data].[dbo].[Company_List_Staging] \n",
    "    FROM\"\"\" + \"\"\" '\"\"\" + directory + \"\"\"\\Tickers.csv' \"\"\" + \"\"\"WITH (FIRSTROW=2,FIELDTERMINATOR = ',',ROWTERMINATOR = '\\n')\"\"\"       \n",
    "    cursor.execute(SQL_string)\n",
    "    cnxn.commit()\n",
    "\n",
    "    SQL_string=\"\"\"Merge [Stock_Data].[dbo].[Company_List] as targ\n",
    "    Using [Stock_Data].[dbo].[Company_List_Staging] as srce on targ.Ticker=srce.Ticker\n",
    "    When Matched then Update Set targ.LastSale=srce.lastSale,targ.MarketCap=srce.MarketCap,targ.ADR_TSO=srce.ADR_TSO\n",
    "    When Not Matched then Insert (Ticker,Name,LastSale,MarketCap,ADR_TSO,IPOyear,Sector,Industry,Summary_Quote,Date_Added) Values (srce.Ticker,srce.Name,srce.LastSale,srce.MarketCap,srce.ADR_TSO,srce.IPOyear,srce.Sector,srce.Industry,srce.Summary_Quote,GetDate());\"\"\"\n",
    "\n",
    "    cursor.execute(SQL_string)\n",
    "    cnxn.commit()\n",
    "    cursor.close()\n",
    "    cnxn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Morningstar Data. times out instead of throwing error.  Will examine more later if needed.  \n",
    "#df_morningstar=pdr.DataReader('AAPL','morningstar',start_date,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google Finance Data. Willl examine more later if needed.  \n",
    "#param = {\n",
    "    #'q': \"TURN\", # Stock symbol (ex: \"AAPL\")\n",
    "    #'i': \"86400\", # Interval size in seconds (\"86400\" = 1 day intervals)\n",
    "    #'x': \"NASD\", # Stock exchange symbol on which stock is traded (ex: \"NASD\")\n",
    "    #'p': \"1Y\" # Period (Ex: \"1Y\" = 1 year)\n",
    "#}\n",
    "# get price data (return pandas dataframe)\n",
    "#df_google = get_price_data(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
